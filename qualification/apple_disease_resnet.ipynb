{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "apple-disease-resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0c499ee30cc47b28e40cdeaa9237863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8a5f6ce5f92f49de85d7d4456c528cfb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_79aa0df3c6844ab1be9c4a5eca7a6733",
              "IPY_MODEL_cbc83b1771ac4f8daff84748399a68de"
            ]
          }
        },
        "8a5f6ce5f92f49de85d7d4456c528cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79aa0df3c6844ab1be9c4a5eca7a6733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ec4a03865e84df79624b57c60e4bc31",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_134363c5eaf7415ebee22ba62bddb873"
          }
        },
        "cbc83b1771ac4f8daff84748399a68de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8fa54ef81dfb4780849c177865df825f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [02:42&lt;00:00, 288kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_075dc6cfc8ff46d780de8f7c95684a55"
          }
        },
        "8ec4a03865e84df79624b57c60e4bc31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "134363c5eaf7415ebee22ba62bddb873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8fa54ef81dfb4780849c177865df825f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "075dc6cfc8ff46d780de8f7c95684a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkCZaBqMkl4H"
      },
      "source": [
        "# Решение задачи \"Классификация болезней яблонь\" RuCode-3\n",
        "\n",
        "В этом ноутбуке будем решать задачу классификации болезней яблонь с помощью предобученной нейронной сети ResNet-18."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev97MPZHy41B"
      },
      "source": [
        "### Скачиваем данные на Google Colab и распаковываем:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlbbYY67oe-F",
        "outputId": "58b958dc-c7ef-44a1-942f-03649f1d0c9b"
      },
      "source": [
        "! wget \"https://s98vla.storage.yandex.net/rdisk/a185914f68628cd93842d4a6a70dcb0d62a16e7e1106bf3c4cd28e1f12c1795e/606b4686/aZ8Akc9CqtcaAMvg9MkExSJefHHGZZYdTl2AU-VqM4afERxsBLTpt8qwBoFEHzTPyT91bTsmoQx6cwIsgiEZFg==?uid=316082386&filename=train.zip&disposition=attachment&hash=&limit=0&content_type=application%2Fzip&owner_uid=316082386&fsize=5901567&hid=539d9e8e45b5325472ea6667b22be86c&media_type=compressed&tknv=v2&etag=e20d5f1607aab3615d9c6dab65c2c61c&rtoken=k4PH1F4bj22Z&force_default=yes&ycrid=na-fea6fc7ef38a35b2c39f5ebc2fe4bc33-downloader5h&ts=5bf3ce4da2d80&s=26c22f6add2ee51ad5e848554e5813842dda62c96e5c279c59069a9102b66992&pb=U2FsdGVkX1_yuow0K5VWKBzcLUifWeCtPIK432oYHEqPxtzC1RqtiodajzZXnCdvCMGe7FZ-BPpY4_9z8aqI1QW47a_-pezgoKSHUVTsePA\" -O train.zip\n",
        "! wget \"https://s147vla.storage.yandex.net/rdisk/b735f673d07382bc37245810c24d803ec6388172b39cfa2b7d092b18b4a6746d/606b46a8/aZ8Akc9CqtcaAMvg9MkExdtkgBWnfCSxc1Dv7y1NU9c9_o0JWRHuxfnP2i148GqPcl3BUbVgs-Mvl1Yht-sqww==?uid=316082386&filename=test_classes.zip&disposition=attachment&hash=&limit=0&content_type=application%2Fzip&owner_uid=316082386&fsize=1341245&hid=ac6712119a1a70fa56686892aa7c81df&media_type=compressed&tknv=v2&etag=22a39c0e331780d6f98d164944612e71&rtoken=eXZekDnBFGGd&force_default=yes&ycrid=na-42fa07d4806adce4d5247aabeb3475a3-downloader5h&ts=5bf3ce6e0fa00&s=6d922208f0d9be353f461565faf3c754e27f77ebdff51d22db0aba01d1a01c98&pb=U2FsdGVkX1_8XZNfYSLPzG0xNmB9O-HQpEf66BsuCdvOR0zUYzcpwqGw3bPCrsY0jrepN-0mHN2_0F8t-FcQMR7OvDIH55r2sHwAfe1PKR0\" -O test_classes.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-05 15:01:11--  https://s98vla.storage.yandex.net/rdisk/a185914f68628cd93842d4a6a70dcb0d62a16e7e1106bf3c4cd28e1f12c1795e/606b4686/aZ8Akc9CqtcaAMvg9MkExSJefHHGZZYdTl2AU-VqM4afERxsBLTpt8qwBoFEHzTPyT91bTsmoQx6cwIsgiEZFg==?uid=316082386&filename=train.zip&disposition=attachment&hash=&limit=0&content_type=application%2Fzip&owner_uid=316082386&fsize=5901567&hid=539d9e8e45b5325472ea6667b22be86c&media_type=compressed&tknv=v2&etag=e20d5f1607aab3615d9c6dab65c2c61c&rtoken=k4PH1F4bj22Z&force_default=yes&ycrid=na-fea6fc7ef38a35b2c39f5ebc2fe4bc33-downloader5h&ts=5bf3ce4da2d80&s=26c22f6add2ee51ad5e848554e5813842dda62c96e5c279c59069a9102b66992&pb=U2FsdGVkX1_yuow0K5VWKBzcLUifWeCtPIK432oYHEqPxtzC1RqtiodajzZXnCdvCMGe7FZ-BPpY4_9z8aqI1QW47a_-pezgoKSHUVTsePA\n",
            "Resolving s98vla.storage.yandex.net (s98vla.storage.yandex.net)... 93.158.162.227, 2a02:6b8:c0e:182:0:41af:3c42:3478\n",
            "Connecting to s98vla.storage.yandex.net (s98vla.storage.yandex.net)|93.158.162.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5901567 (5.6M) [application/zip]\n",
            "Saving to: ‘train.zip’\n",
            "\n",
            "train.zip           100%[===================>]   5.63M  14.8MB/s    in 0.4s    \n",
            "\n",
            "2021-04-05 15:01:12 (14.8 MB/s) - ‘train.zip’ saved [5901567/5901567]\n",
            "\n",
            "--2021-04-05 15:01:12--  https://s147vla.storage.yandex.net/rdisk/b735f673d07382bc37245810c24d803ec6388172b39cfa2b7d092b18b4a6746d/606b46a8/aZ8Akc9CqtcaAMvg9MkExdtkgBWnfCSxc1Dv7y1NU9c9_o0JWRHuxfnP2i148GqPcl3BUbVgs-Mvl1Yht-sqww==?uid=316082386&filename=test_classes.zip&disposition=attachment&hash=&limit=0&content_type=application%2Fzip&owner_uid=316082386&fsize=1341245&hid=ac6712119a1a70fa56686892aa7c81df&media_type=compressed&tknv=v2&etag=22a39c0e331780d6f98d164944612e71&rtoken=eXZekDnBFGGd&force_default=yes&ycrid=na-42fa07d4806adce4d5247aabeb3475a3-downloader5h&ts=5bf3ce6e0fa00&s=6d922208f0d9be353f461565faf3c754e27f77ebdff51d22db0aba01d1a01c98&pb=U2FsdGVkX1_8XZNfYSLPzG0xNmB9O-HQpEf66BsuCdvOR0zUYzcpwqGw3bPCrsY0jrepN-0mHN2_0F8t-FcQMR7OvDIH55r2sHwAfe1PKR0\n",
            "Resolving s147vla.storage.yandex.net (s147vla.storage.yandex.net)... 77.88.39.37, 2a02:6b8:c0e:74f:0:41af:2f16:6c1f\n",
            "Connecting to s147vla.storage.yandex.net (s147vla.storage.yandex.net)|77.88.39.37|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1341245 (1.3M) [application/zip]\n",
            "Saving to: ‘test_classes.zip’\n",
            "\n",
            "test_classes.zip    100%[===================>]   1.28M  4.63MB/s    in 0.3s    \n",
            "\n",
            "2021-04-05 15:01:13 (4.63 MB/s) - ‘test_classes.zip’ saved [1341245/1341245]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOSmHAFKo_ad"
      },
      "source": [
        "! unzip train.zip\n",
        "! unzip test_classes.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkxJHdYUpDgw",
        "outputId": "1d50758c-1bad-4655-e51a-d3aece5eaf28"
      },
      "source": [
        "! ls test_classes/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0_гниль  1_ржавчина  2_парша\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwAQe3qIy_Tg"
      },
      "source": [
        "### Строим нейросеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2gjKiikpFZR"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.models as models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcxQQTxonFM2"
      },
      "source": [
        "Создаем даталоадеры для обучения нейросети:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45oPiZW6pbEf"
      },
      "source": [
        "images_dataset = torchvision.datasets.ImageFolder(\"./train\", transform=transforms.Compose([                                                                  \n",
        "  transforms.ToTensor(),\n",
        "  # нормализуем как в ImageNet\n",
        "  torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                   [0.229, 0.224, 0.225]),\n",
        "                                                                                                    \n",
        "]))\n",
        "\n",
        "images_dataloader = torch.utils.data.DataLoader(images_dataset, batch_size=16,\n",
        "                                          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO1cSJGWzHke"
      },
      "source": [
        "Будем использовать предобученную на ImageNet сеть ResNet18:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b0c499ee30cc47b28e40cdeaa9237863",
            "8a5f6ce5f92f49de85d7d4456c528cfb",
            "79aa0df3c6844ab1be9c4a5eca7a6733",
            "cbc83b1771ac4f8daff84748399a68de",
            "8ec4a03865e84df79624b57c60e4bc31",
            "134363c5eaf7415ebee22ba62bddb873",
            "8fa54ef81dfb4780849c177865df825f",
            "075dc6cfc8ff46d780de8f7c95684a55"
          ]
        },
        "id": "1WJSH04Rp5UH",
        "outputId": "8bb2209b-fb53-497f-d5e2-f4410a5c9d0d"
      },
      "source": [
        "net = models.resnet18(True, True).cuda() \n",
        "net  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0c499ee30cc47b28e40cdeaa9237863",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvUfblEyzN77"
      },
      "source": [
        "Заменим последний полносвязный слой сети на слой, который будет выдавать 3 значения на выходе (т.к. у нас 3 класса):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgR8ryswqANs"
      },
      "source": [
        "net.fc = nn.Linear(512, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeo5dBgqxtbr"
      },
      "source": [
        "Заморозим все слом нейросети, кроме самого последнего, только что добавленного fc-слоя. Будем обучать только последний слой сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvK5-N6xvFO0"
      },
      "source": [
        "for i, child in enumerate(net.children()):\n",
        "    if i == 9: \n",
        "        break\n",
        "    for param in child.parameters():\n",
        "        param.requires_grad = False  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AG_B9zhzY30"
      },
      "source": [
        "Объявляем лосс-функцию и оптимизатор:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sna0XTltvObQ"
      },
      "source": [
        "# стандартная лосс-функция для задачи классификации\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWaOwvCnvnmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cdd485-f885-4d6f-d1cf-42349a49fa74"
      },
      "source": [
        "# для обучения на GPU\n",
        "device = 'cuda:0'\n",
        "net.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqGTCY7wzcqN"
      },
      "source": [
        "Обучаем сеть 5 эпох:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBYQPZx4vUQO",
        "outputId": "19864183-bc88-4eb0-faf9-063ac56c84ec"
      },
      "source": [
        "n_epochs = 5\n",
        "print_every = 10\n",
        "\n",
        "total_step = len(images_dataloader)\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    print(f'Epoch {epoch}\\n')\n",
        "    for batch_idx, (data, target) in enumerate(images_dataloader):\n",
        "        # кладем данные на GPU\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # делаем шаг обучения сети\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(data)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (batch_idx) % 20 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "\n",
            "Epoch [1/5], Step [0/25], Loss: 1.1735\n",
            "Epoch [1/5], Step [20/25], Loss: 0.7808\n",
            "Epoch 2\n",
            "\n",
            "Epoch [2/5], Step [0/25], Loss: 0.6210\n",
            "Epoch [2/5], Step [20/25], Loss: 0.3811\n",
            "Epoch 3\n",
            "\n",
            "Epoch [3/5], Step [0/25], Loss: 0.3694\n",
            "Epoch [3/5], Step [20/25], Loss: 0.2428\n",
            "Epoch 4\n",
            "\n",
            "Epoch [4/5], Step [0/25], Loss: 0.2725\n",
            "Epoch [4/5], Step [20/25], Loss: 0.1689\n",
            "Epoch 5\n",
            "\n",
            "Epoch [5/5], Step [0/25], Loss: 0.1234\n",
            "Epoch [5/5], Step [20/25], Loss: 0.2875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOyInJ-ZyLUW"
      },
      "source": [
        "### Тестируем обученную нейросеть на тестовом наборе картинок:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5RGwLlkwA_U"
      },
      "source": [
        "images_testset = torchvision.datasets.ImageFolder(\"./test_classes\", transform=transforms.Compose([                                                                  \n",
        "  transforms.ToTensor(),\n",
        "  torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                   [0.229, 0.224, 0.225]),\n",
        "                                                                                                    \n",
        "]))\n",
        "\n",
        "images_testloader = torch.utils.data.DataLoader(images_testset, batch_size=1,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99RrK4vAqoIo",
        "outputId": "87c5bc16-3953-4147-dbf9-9a12b3049c58"
      },
      "source": [
        "batch_loss = 0\n",
        "total=0\n",
        "correct=0\n",
        "\n",
        "with torch.no_grad():\n",
        "        net.eval()\n",
        "\n",
        "        for data, target in (images_testloader):\n",
        "            # кладем данные на GPU\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = net(data)\n",
        "            # считаем loss\n",
        "            loss = criterion(outputs, target)\n",
        "            batch_loss += loss.item()\n",
        "\n",
        "            # считаем accuracy\n",
        "            _, pred = torch.max(outputs, dim=1)\n",
        "            correct += torch.sum(pred==target).item()\n",
        "            total += target.size(0)\n",
        "\n",
        "        print(\"Acc\", 100 * correct/total)\n",
        "        print(\"Loss\", batch_loss/len(images_testloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc 100.0\n",
            "Loss 0.1592358947162413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTaR9VqQzgRI"
      },
      "source": [
        "Вуаля!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2cFAM43zg-z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}